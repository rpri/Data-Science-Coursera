library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
source('~/res/Reg1.r')
source('~/res/Reg1.r')
install.packages(“caret”)
install.packages('caret'')
hbhjb
install.packages("caret")
install.packages("caret")
install.packages("AppliedPredictiveModeling")
source('~/res/Reg1.r')
install.packages("leAFL")
source('~/res/Reg1.r')
install.packages("leaflet")
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
source('~/res/Reg1.r')
install.packages("plotly")
source('~/res/Assignment 3.R')
source('~/res/Assignment 3.R')
source('~/res/Assignment 3.R')
source('~/res/Assignment 3.R')
source('~/res/Assignment 3.R')
source('~/res/Assignment 3.R')
source('~/res/Assignment 3.R')
source('~/res/Assignment 3.R')
source('~/res/Assignment 3.R')
View(d)
shiny::runApp('res/myApp')
runApp('res/myApp')
runApp('res/myApp')
runApp('res/myApp')
install.packages("rsconnect")
rsconnect::setAccountInfo(name='rpri',
token='7153B19A2F646A986AD2CA041DEB515B',
secret='<SECRET>')
rsconnect::setAccountInfo(name='rpri', token='7153B19A2F646A986AD2CA041DEB515B', secret='IY2KGq+xxYvJr5vdQTJjMvOiSpXFKwVghkue2rKy')
library(rsconnect)
rsconnect::deployApp('path/to/your/app')
shiny::runApp()
runApp()
runApp()
install.packages("rpart.plot")
install.packages("randomForest")
install.packages("randomForest")
install.packages("corrplot")
install.packages("lubridate")
install.packages("e1071")
knitr::opts_chunk$set(echo = TRUE)
library(caret)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(rpart)
library(corrplot)
library(rpart.plot)
library(randomForest)
library(dplyr)
library(lubridate)
ptrain<-read.csv("pml-training.csv",na.strings = c("NA","","#DIV/0"))
ptest<-read.csv("pml-testing.csv",na.strings = c("NA","","#DIV/0"))
dim(ptrain)
dim(ptest)
set.seed(10)
inTrain<-createDataPartition(y=ptrain$classe,p=0.6,list=FALSE)
dataTrain1<-ptrain[inTrain,]
dataTrain2<-ptrain[-inTrain,]
#remove variables with near zero variance
nzv<-nearZeroVar(dataTrain1)
dataTrain1<-dataTrain1[,-nzv]
dataTrain2<-dataTrain2[,-nzv]
#remove variables that are almost always NA
almostNA<-sapply(dataTrain1,function(x) mean(is.na(x))) >0.95
dataTrain1<-dataTrain1[,almostNA==F]
dataTrain2<-dataTrain2[,almostNA==F]
#remove variables that dont make sense for prediction (x,user_name, raw_timestamp_part_1 ,raw_timestamp_part_2,cvtd_timestamp),which happen to be first 5 variables
dataTrain1<-dataTrain1[,-(1:5)]
dataTrain2<-dataTrain2[,-(1:5)]
#use train to use 5-fold CV to select optimal parameters
fitcontrol<-trainControl(method="cv",number=5,verboseIter = F)
#fit model on training data 1
fit<-train(dataTrain1$classe~.,data=dataTrain1,method="rf",trControl=fitcontrol)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(rpart)
library(corrplot)
library(rpart.plot)
library(randomForest)
library(dplyr)
library(lubridate)
ptrain<-read.csv("pml-training.csv",na.strings = c("NA","","#DIV/0"))
ptest<-read.csv("pml-testing.csv",na.strings = c("NA","","#DIV/0"))
dim(ptrain)
dim(ptest)
set.seed(10)
inTrain<-createDataPartition(y=ptrain$classe,p=0.6,list=FALSE)
dataTrain1<-ptrain[inTrain,]
dataTrain2<-ptrain[-inTrain,]
#remove variables with near zero variance
nzv<-nearZeroVar(dataTrain1)
dataTrain1<-dataTrain1[,-nzv]
dataTrain2<-dataTrain2[,-nzv]
#remove variables that are almost always NA
almostNA<-sapply(dataTrain1,function(x) mean(is.na(x))) >0.95
dataTrain1<-dataTrain1[,almostNA==F]
dataTrain2<-dataTrain2[,almostNA==F]
#remove variables that dont make sense for prediction (x,user_name, raw_timestamp_part_1 ,raw_timestamp_part_2,cvtd_timestamp),which happen to be first 5 variables
dataTrain1<-dataTrain1[,-(1:5)]
dataTrain2<-dataTrain2[,-(1:5)]
#use train to use 5-fold CV to select optimal parameters
fitcontrol<-trainControl(method="cv",number=5,verboseIter = F)
#fit model on training data 1
fit<-train(dataTrain1$classe~.,data=dataTrain1,method="rf",trControl=fitcontrol)
#use train to use 5-fold CV to select optimal parameters
fitcontrol<-trainControl(method="cv",number=5,verboseIter = F)
#fit model on training data 1
fit<-train(dataTrain1$classe ~.,data=dataTrain1,method="rf",trControl=fitcontrol)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(rpart)
library(corrplot)
library(rpart.plot)
library(randomForest)
library(dplyr)
library(lubridate)
ptrain<-read.csv("pml-training.csv",na.strings = c("NA","","#DIV/0"))
ptest<-read.csv("pml-testing.csv",na.strings = c("NA","","#DIV/0"))
dim(ptrain)
dim(ptest)
set.seed(10)
inTrain<-createDataPartition(y=ptrain$classe,p=0.6,list=FALSE)
dataTrain1<-ptrain[inTrain,]
dataTrain2<-ptrain[-inTrain,]
#remove variables with near zero variance
nzv<-nearZeroVar(dataTrain1)
dataTrain1<-dataTrain1[,-nzv]
dataTrain2<-dataTrain2[,-nzv]
#remove variables that are almost always NA
almostNA<-sapply(dataTrain1,function(x) mean(is.na(x))) >0.95
dataTrain1<-dataTrain1[,almostNA==F]
dataTrain2<-dataTrain2[,almostNA==F]
#remove variables that dont make sense for prediction (x,user_name, raw_timestamp_part_1 ,raw_timestamp_part_2,cvtd_timestamp),which happen to be first 5 variables
dataTrain1<-dataTrain1[,-(1:5)]
dataTrain2<-dataTrain2[,-(1:5)]
#use train to use 5-fold CV to select optimal parameters
fitcontrol<-trainControl(method="cv",number=5,verboseIter = F)
#fit model on training data 1
fit<-train(dataTrain1$classe ~ .,data=dataTrain1,method="rf", trControl = fitcontrol )
shiny::runApp()
runApp()
runApp('~/res/Toothanalysis')
runApp('~/res/Toothanalysis')
runApp('~/res/Toothanalysis')
runApp('~/res/Toothanalysis')
runApp('~/res/Toothanalysis')
